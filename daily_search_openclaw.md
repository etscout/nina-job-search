# Daily Search Task for OpenClaw

This is the task that should be run by OpenClaw cron job daily at 7 AM.

## Task

Execute the full Nina job search pipeline:

1. Load search queries from `search_queries.json` (generated by `search_jobs.py`)
2. Execute web_search for each query using the web_search tool
3. Compile results into `raw_jobs.json` using `openclaw_search.py`
4. Run `run_daily.py` to:
   - Score jobs
   - Validate URLs
   - Add to database
   - Send email if new jobs found

## Steps

```python
import json
import sys
sys.path.insert(0, '/home/ck/nina-job-search')

from search_jobs import generate_search_queries
from openclaw_search import compile_search_results, save_raw_jobs
import subprocess

# Step 1: Generate queries
print("Generating search queries...")
queries = generate_search_queries()
print(f"Generated {len(queries)} queries")

# Step 2: Execute searches
print("\nExecuting web searches...")
all_results = []

for i, query in enumerate(queries, 1):
    print(f"[{i}/{len(queries)}] Searching: {query[:60]}...")
    
    # Use OpenClaw's web_search tool
    results = web_search(query=query, count=5)
    
    if results:
        all_results.extend(results.get('results', []))
    
    # Small delay to avoid rate limits
    import time
    time.sleep(0.5)

print(f"Found {len(all_results)} total results")

# Step 3: Compile into jobs
print("\nCompiling job listings...")
jobs = compile_search_results(all_results)
print(f"Extracted {len(jobs)} job listings")

# Step 4: Save raw jobs
save_raw_jobs(jobs, '/home/ck/nina-job-search/raw_jobs.json')

# Step 5: Run the daily pipeline
print("\nRunning daily pipeline...")
result = subprocess.run(
    ['python3', 'run_daily.py'],
    cwd='/home/ck/nina-job-search',
    capture_output=True,
    text=True
)

print(result.stdout)
if result.stderr:
    print("ERRORS:", result.stderr)

if result.returncode == 0:
    print("\n✅ Daily search complete!")
else:
    print("\n❌ Daily search failed!")
```

## Cron Job Setup

```bash
# Create cron job for 7 AM PST (15:00 UTC) daily
openclaw cron add --job '{
  "name": "Nina Daily Job Search",
  "schedule": {
    "kind": "cron",
    "expr": "0 15 * * *",
    "tz": "UTC"
  },
  "payload": {
    "kind": "agentTurn",
    "message": "Run the Nina job search: cd /home/ck/nina-job-search && cat daily_search_openclaw.md and execute the task described in it.",
    "model": "anthropic/claude-sonnet-4",
    "timeoutSeconds": 600
  },
  "sessionTarget": "isolated",
  "enabled": true
}'
```

## Manual Run

```bash
cd /home/ck/nina-job-search

# Generate queries
python3 search_jobs.py

# (Execute searches via OpenClaw - see above)

# Run pipeline
python3 run_daily.py

# Or just send email from database
python3 send_email.py
```

## Monitor

```bash
# View web dashboard
cd /home/ck/nina-job-search
python3 app.py
# Visit http://localhost:5000

# Check database stats
sqlite3 nina_jobs.db "SELECT COUNT(*) FROM jobs"
sqlite3 nina_jobs.db "SELECT COUNT(*) FROM jobs WHERE sent_in_email = 0"
```
